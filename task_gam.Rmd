---
title: "GAM task"
author: "Sam Clifford and Megan Verma"
date: "07/06/2022"
output: 
  html_document:
      citation_package: natbib
bibliography: "MeganVerma.bib"
biblio-style: "chicago"
link-citations: true
---

``` {r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Introduction

This R Markdown document is designed to get you used to working with the type of data that we'll need to do the modelling in the MSc project itself. Clone the repository and make sure you commit changes regularly.

## Loading packages

``` {r, eval = TRUE}
library(tidyverse)
library(mgcv)
```

## Data preparation

Load the data that you used to fit the GLM models in the previous task. Ensure that you have a data frame containing the Gini coefficient, UN subregion, cases per million, population, average household size, and GDP per capita.

## Modelling with splines

Splines are a member of the class of functions called 'scatterplot smoothers'. They provide a way to estimate the association between an outcome variable and an explanatory variable without specifying what the form of the function will be (e.g. linear, polynomial, sinusoidal) which improves flexibility but at the cost of direct interpretability [@gamair]. 

The mgcv package in R provides a way to fit Generalised Additive Models, an extension to GLMs where we replace the linear terms in the model with scatterplot smoothers. The model fitting syntax of mgcv's `gam()` function is based on `glm()` but the formula uses `s(x, ...)` to represent a smooth function of `x` rather than just a linear function of it, e.g.

``` {r, eval=FALSE}

gam(data = my_data, y ~ s(x))

```

## Fitting a model

In the previous GLM task we fit a Binomial regression model where the explanatory variable was the log of per capita GDP, a linear effect of log-GDP. Replace the linear effect of log-GDP with a smooth function of log-GDP.

``` {r}
NULL
```

All GLMs are GAMs. Re-fit the GLM model using the `gam()` function; everything internal should remain the same as in the GLM task.

``` {r}
NULL
```

## Model diagnostics

Look at the summary of each of the two models. Can you tell whether or not the GAM  with the scatterplot smoother gives a significantly better fit than the model with only a linear term?

First, let's look at the fitted smooth function. This is quite an ugly plot using the base R plotting tools, but it's still informative.

``` {r}
plot(NULL)
```

On the left hand $y$ axis you should see something of the form `s(x, edf)` where `x` is the variable name and `edf` is the effective degrees of freedom in the smooth function. We can think of this as how complex a polynomial would need to be to provide the same fit. If `edf` is 1, then the wiggliness penalty that is used on splines in mgcv suggests that a straight line is the most supported shape of the curve. In fact, passing `select=TRUE` as an argument to `gam()` allows the penalisation of the curve to be the zero function (i.e. $s(x) \equiv 0$), doing model selection on the fly to remove `s(x)` from the model.

Is your smooth function a straight line?

<!-- If it is not, it can be useful to use ANOVA on the fitted models to determine whether the more complex model does indeed perform better.  -->

## Model comparison

For linear models we can do model comparison with analysis of variance (ANOVA) using R's `anova()` function (which has a method for the `lm` class). This compares the residual sum of squares of two models (unexplained variation) and performs an $F$ test to determine whether the change in sum of squares is statistically significant. ANOVA on LMs requires that the models be nested, i.e. one of the models can be recovered from the other by removing terms. ANOVA on our GLM and GAM models can be done, of sorts, by calling `anova()` on `glm` and `gam` objects in R and this provides an analysis of deviance table using the Generalised Likelihood Ratio Test (GLRT).

The GLRT allows us to compare non-nested models that are fit to the same $\boldsymbol{y}$ but may contain different covariate effects, comparing their deviance. Recall that the model's likelihood is the function that expresses the probability of the observed data under the assumed model with a given set of parameters.

$$
\mathcal{L} \left( \boldsymbol{\theta} \middle| \boldsymbol{y} \right) = \prod\limits_{i=1}^n f(y_i, \boldsymbol{\theta}, \boldsymbol{x}_i)
$$
where $f(\cdot)$ is a probability density function $p\left(\boldsymbol{y} \middle| \boldsymbol{\theta}, \boldsymbol{x} \right)$ describing a model of how likely it is to see the observed $\boldsymbol{y}$ given some covariates, $\boldsymbol{x}$, and model parameters $\boldsymbol{\theta}$.

For a given model structure, we often seek the parameters that maximise the likelihood function (maximum likelihood estimation). Comparing two likelihoods is therefore a natural thing to do in order to determine which of two models is better.

It's appropriate, however, to consider that the extra goodness of fit comes as a result of adding extra (or, different, at least) terms and using more parameters to explain the variability. The Akaike Information Criterion [@Akaike1974] and extensions to it [@MARRA20112372] add a penalty to the maximum likelihood estimate of a model with a model whose likelihood, $\mathcal{L}$, is maximised for parameter values $\widehat{\boldsymbol{\theta}}$ and has $k$ effective degrees of freedom,

$$
\mathrm{AIC} = -2 \log \mathcal{L} \left(\widehat{\boldsymbol{\theta}} \middle| \boldsymbol{y} \right) + 2k.
$$

Out of two models being compared, $M_1$ and $M_2$, we should favour the one with the smallest AIC. If two models are just as complex as each other, $k_1 = k_2$, we should choose the one that provides the better fit (higher likelihood). If the two models perform as well as each other we should choose the less complex one. In practice, the trade-off between simpler model and better fit means will probably select a model which has many more parameters but yields a much better fit although we may occasionally favour a model which has a slightly poorer fit but is much simpler.

Using the `glance()` function from the broom package, extract the AIC for the GAM models that have a linear function of log-GDP and a smooth function of log-GDP.

``` {r}
library(broom)
NULL
```

Which model is preferred?

Now fit a GAM that relates the number of cases to a smooth function of the Gini coefficient.

``` {r}
NULL
```

Using the AIC, which model is preferred out of the Gini coefficient GAM and the log-GDP GAM?

``` {r}
NULL
```


Fit a GAM that contains smooth functions of all of the following: the Gini coefficient, log-GDP, and average household size. Ensure that you also have models that contain each of these individually.

``` {r}
NULL
```


For each of the models with only one smooth function, plot the fitted smooth function. Save these graphs.

``` {r}
NULL
```

Plot the fitted smooths for the model with all three covariates. NB: setting `pages = 1` makes sure that all the smooths are contained in the same image rather than being printed separately.

``` {r, eval = FALSE}
plot(NULL, pages = 1)
```

What happens to the each of the fitted smooths when you compare each of the individual covariate models to the combined model? Think of both the overall shape, and the effective degrees of freedom.

Calculate the AIC for all four of the models. Which model is preferred?

``` {r}
NULL
```

Using functional programming in the purrr package we can simplify the calculation a little if you want, reducing the number of times we copy-paste the same code.

``` {r}
list(`log-GDP`           = NULL, # replace NULL with model object name
     `Gini`              = NULL,
     `Average household` = NULL,
     `Combined`          = NULL) %>%
  map_df(~glance(.x), .id = "Model") %>%
  dplyr::select(Model, logLik, df, AIC)
```

The above code says 'make a list of models' and then 'apply the `glance()` function to everything in the list', returning the results as a data frame with a column called `Model` that contains the names from the list, and then 'select only these columns'.

## References


